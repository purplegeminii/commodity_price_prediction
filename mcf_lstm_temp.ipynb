{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e378bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/tqc_535n6bb2mkqrf4_7nf6w0000gn/T/ipykernel_12974/725386740.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill')\n",
      "/var/folders/rd/tqc_535n6bb2mkqrf4_7nf6w0000gn/T/ipykernel_12974/725386740.py:24: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill')\n",
      "/var/folders/rd/tqc_535n6bb2mkqrf4_7nf6w0000gn/T/ipykernel_12974/725386740.py:33: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill')\n",
      "/var/folders/rd/tqc_535n6bb2mkqrf4_7nf6w0000gn/T/ipykernel_12974/725386740.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data still contains NaN values after filling",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[32m    215\u001b[39m df = load_and_preprocess_data()\n\u001b[32m    216\u001b[39m df = add_rolling_features(df, commodity_cols)\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m df = \u001b[43madd_lagged_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Prepare sequences\u001b[39;00m\n\u001b[32m    220\u001b[39m n_steps = \u001b[32m12\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36madd_lagged_features\u001b[39m\u001b[34m(df, feature_cols)\u001b[39m\n\u001b[32m     34\u001b[39m df.fillna(method=\u001b[33m'\u001b[39m\u001b[33mbfill\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df.isnull().values.any():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mData still contains NaN values after filling\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[31mValueError\u001b[39m: Data still contains NaN values after filling"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "def load_and_preprocess_data():\n",
    "    df = pd.read_csv(\"merged_macro_commodity.csv\", parse_dates=['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_rolling_features(df, commodity_cols):\n",
    "    \"\"\"Add rolling features inspired by Prophet implementation\"\"\"\n",
    "    for commodity in commodity_cols:\n",
    "        df[f'{commodity}_3mo_ma'] = df[commodity].rolling(3, min_periods=1).mean()\n",
    "        # df[f'{commodity}_12mo_ma'] = df[commodity].rolling(12, min_periods=6).mean()\n",
    "    df.fillna(method='ffill')\n",
    "    df.fillna(method='bfill')\n",
    "    if df.isnull().values.any():\n",
    "        raise ValueError(\"Data still contains NaN values after filling\")\n",
    "    return df\n",
    "\n",
    "def add_lagged_features(df, feature_cols):\n",
    "    \"\"\"Add lagged macroeconomic features\"\"\"\n",
    "    for feature in feature_cols:\n",
    "        df[f'{feature}_lag3'] = df[feature].shift(3)\n",
    "    df.fillna(method='ffill')\n",
    "    df.fillna(method='bfill')\n",
    "    if df.isnull().values.any():\n",
    "        raise ValueError(\"Data still contains NaN values after filling\")\n",
    "    return df\n",
    "\n",
    "# 2. Model Configuration\n",
    "commodity_cols = ['Crude Oil Brent Price', 'Cocoa Price', 'Gold Price']\n",
    "feature_cols = ['Revenue, excluding grants (% of GDP)', \n",
    "               'GDP (constant 2015 US$)', \n",
    "               'Employment to population ratio (15+, total %)']\n",
    "\n",
    "# Commodity-specific parameters (extended from Prophet config)\n",
    "commodity_params = {\n",
    "    'Crude Oil Brent Price': {\n",
    "        'lstm_units1': 256,\n",
    "        'lstm_units2': 128,\n",
    "        'dropout1': 0.3,\n",
    "        'dropout2': 0.2,\n",
    "        'learning_rate': 0.0005,\n",
    "        'epochs': 150,\n",
    "        'batch_size': 32,\n",
    "        'floor': 20,\n",
    "        'cap': 150\n",
    "    },\n",
    "    'Cocoa Price': {\n",
    "        'lstm_units1': 128,\n",
    "        'lstm_units2': 64,\n",
    "        'dropout1': 0.2,\n",
    "        'dropout2': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 16,\n",
    "        'floor': 1,\n",
    "        'cap': 10\n",
    "    },\n",
    "    'Gold Price': {\n",
    "        'lstm_units1': 192,\n",
    "        'lstm_units2': 96,\n",
    "        'dropout1': 0.25,\n",
    "        'dropout2': 0.15,\n",
    "        'learning_rate': 0.00075,\n",
    "        'epochs': 120,\n",
    "        'batch_size': 24,\n",
    "        'floor': 150,\n",
    "        'cap': 2500\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_lstm_model(input_shape, commodity_name):\n",
    "    \"\"\"Create commodity-specific LSTM model\"\"\"\n",
    "    params = commodity_params[commodity_name]\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(params['lstm_units1'], \n",
    "             activation='tanh', \n",
    "             return_sequences=True, \n",
    "             input_shape=input_shape),\n",
    "        Dropout(params['dropout1']),\n",
    "        LSTM(params['lstm_units2'], activation='tanh'),\n",
    "        Dropout(params['dropout2']),\n",
    "        Dense(len(commodity_cols))  # Multi-output\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 3. Data Processing Pipeline\n",
    "def prepare_data(df, n_steps=12):\n",
    "    \"\"\"Prepare data for LSTM with Prophet-inspired features\"\"\"\n",
    "    # Scale data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - n_steps):\n",
    "        X.append(scaled_data[i:i+n_steps, :])\n",
    "        y.append(scaled_data[i+n_steps, :len(commodity_cols)])  # Predict commodities only\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "# 4. Training and Evaluation\n",
    "def train_model(model, X_train, y_train, commodity_name):\n",
    "    \"\"\"Train with early stopping\"\"\"\n",
    "    params = commodity_params[commodity_name]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, scaler):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    # Predict and inverse transform\n",
    "    y_pred = model.predict(X_test)\n",
    "    dummy = np.zeros((len(y_pred), scaler.n_features_in_))\n",
    "    dummy[:,:len(commodity_cols)] = y_pred\n",
    "    y_pred = scaler.inverse_transform(dummy)[:,:len(commodity_cols)]\n",
    "    \n",
    "    # Inverse transform actuals\n",
    "    dummy[:,:len(commodity_cols)] = y_test\n",
    "    y_test_actual = scaler.inverse_transform(dummy)[:,:len(commodity_cols)]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    for i, col in enumerate(commodity_cols):\n",
    "        # mae = mean_absolute_error(y_test_actual[:,i], y_pred[:,i])\n",
    "        mape = np.mean(np.abs((y_test_actual[:,i] - y_pred[:,i]) / y_test_actual[:,i])) * 100\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_actual[:,i], y_pred[:,i]))\n",
    "        metrics[col] = {'MAPE': mape, 'RMSE': rmse}\n",
    "    \n",
    "    return metrics, y_pred\n",
    "\n",
    "# 5. Forecasting\n",
    "def make_forecasts(model, X, n_steps, forecast_steps, scaler):\n",
    "    \"\"\"Generate recursive forecasts\"\"\"\n",
    "    forecasts = []\n",
    "    current_batch = X[-1:]  # Most recent sequence\n",
    "    \n",
    "    for _ in range(forecast_steps):\n",
    "        # Predict next step\n",
    "        current_pred = model.predict(current_batch, verbose=0)[0]\n",
    "        forecasts.append(current_pred)\n",
    "        \n",
    "        # Update batch with prediction\n",
    "        new_row = np.concatenate([\n",
    "            current_pred,\n",
    "            scaler.transform(df.iloc[-1:])[0, len(commodity_cols):]  # Latest features\n",
    "        ]).reshape(1, 1, -1)\n",
    "        \n",
    "        current_batch = np.concatenate([\n",
    "            current_batch[:, 1:, :],  # Remove oldest\n",
    "            new_row  # Add new prediction\n",
    "        ], axis=1)\n",
    "    \n",
    "    # Inverse transform\n",
    "    dummy = np.zeros((len(forecasts), scaler.n_features_in_))\n",
    "    dummy[:,:len(commodity_cols)] = forecasts\n",
    "    return scaler.inverse_transform(dummy)[:,:len(commodity_cols)]\n",
    "\n",
    "# 6. Visualization\n",
    "def plot_results(commodity_idx, y_test, y_pred, forecasts, test_dates, forecast_dates):\n",
    "    \"\"\"Plot results in Prophet-style\"\"\"\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Historical data\n",
    "    plt.plot(df.index[:-len(y_test)], df.iloc[:-len(y_test), commodity_idx], \n",
    "             'b-', label='Historical')\n",
    "    \n",
    "    # Test actuals\n",
    "    plt.plot(test_dates, y_test[:, commodity_idx], \n",
    "             'k-', label='Actual')\n",
    "    \n",
    "    # Test predictions\n",
    "    plt.plot(test_dates, y_pred[:, commodity_idx], \n",
    "             'r-', label='Test Predictions', alpha=0.7)\n",
    "    \n",
    "    # Forecasts\n",
    "    plt.plot(forecast_dates, forecasts[:, commodity_idx], \n",
    "             'go--', label='Forecast')\n",
    "    \n",
    "    plt.title(f'{commodity_cols[commodity_idx]} Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    df = load_and_preprocess_data()\n",
    "    df = add_rolling_features(df, commodity_cols)\n",
    "    df = add_lagged_features(df, feature_cols)\n",
    "    \n",
    "    # Prepare sequences\n",
    "    n_steps = 12\n",
    "    X, y, scaler = prepare_data(df, n_steps)\n",
    "    \n",
    "    # Train-test split (temporal)\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    # Train models\n",
    "    models = {}\n",
    "    histories = {}\n",
    "    \n",
    "    for commodity in commodity_cols:\n",
    "        print(f\"\\nTraining {commodity} model...\")\n",
    "        model = create_lstm_model((n_steps, X.shape[2]), commodity)\n",
    "        history = train_model(model, X_train, y_train, commodity)\n",
    "        models[commodity] = model\n",
    "        histories[commodity] = history\n",
    "        \n",
    "        # Plot training history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.title(f'{commodity} Training History')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # Evaluate models\n",
    "    test_dates = df.index[n_steps+train_size:-n_steps]\n",
    "    all_metrics = {}\n",
    "    \n",
    "    for i, commodity in enumerate(commodity_cols):\n",
    "        metrics, y_pred = evaluate_model(models[commodity], X_test, y_test, scaler)\n",
    "        all_metrics[commodity] = metrics[commodity]  # Since we predict all commodities together\n",
    "        \n",
    "        print(f\"\\n{commodity} Test Metrics:\")\n",
    "        # print(f\"MAE: {metrics[commodity]['MAE']:.2f}\")\n",
    "        print(f\"MAPE: {metrics[commodity]['MAPE']:.2f}%\")\n",
    "        print(f\"RMSE: {metrics[commodity]['RMSE']:.2f}\")\n",
    "    \n",
    "    # Generate and plot forecasts\n",
    "    forecast_steps = 12\n",
    "    forecast_dates = pd.date_range(start=df.index[-1], periods=forecast_steps+1, freq='M')[1:]\n",
    "    \n",
    "    for i, commodity in enumerate(commodity_cols):\n",
    "        forecasts = make_forecasts(models[commodity], X_test, n_steps, forecast_steps, scaler)\n",
    "        plot_results(i, \n",
    "                   scaler.inverse_transform(y_test.reshape(-1, len(commodity_cols))), \n",
    "                   y_pred, \n",
    "                   forecasts, \n",
    "                   test_dates, \n",
    "                   forecast_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f680bebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue, excluding grants (% of GDP)</th>\n",
       "      <th>GDP (constant 2015 US$)</th>\n",
       "      <th>Employment to population ratio (15+, total %)</th>\n",
       "      <th>Crude Oil Brent Price</th>\n",
       "      <th>Cocoa Price</th>\n",
       "      <th>Gold Price</th>\n",
       "      <th>Crude Oil Brent Price_3mo_ma</th>\n",
       "      <th>Cocoa Price_3mo_ma</th>\n",
       "      <th>Gold Price_3mo_ma</th>\n",
       "      <th>Revenue, excluding grants (% of GDP)_lag3</th>\n",
       "      <th>GDP (constant 2015 US$)_lag3</th>\n",
       "      <th>Employment to population ratio (15+, total %)_lag3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-01-01</th>\n",
       "      <td>14.597519</td>\n",
       "      <td>1.386282e+10</td>\n",
       "      <td>74.834000</td>\n",
       "      <td>23.65</td>\n",
       "      <td>1.2417</td>\n",
       "      <td>383.64</td>\n",
       "      <td>23.650000</td>\n",
       "      <td>1.241700</td>\n",
       "      <td>383.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02-01</th>\n",
       "      <td>14.372773</td>\n",
       "      <td>1.391355e+10</td>\n",
       "      <td>74.690804</td>\n",
       "      <td>19.40</td>\n",
       "      <td>1.2147</td>\n",
       "      <td>363.83</td>\n",
       "      <td>21.525000</td>\n",
       "      <td>1.228200</td>\n",
       "      <td>373.735000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03-01</th>\n",
       "      <td>14.148027</td>\n",
       "      <td>1.396124e+10</td>\n",
       "      <td>74.556498</td>\n",
       "      <td>19.45</td>\n",
       "      <td>1.2103</td>\n",
       "      <td>363.34</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>1.222233</td>\n",
       "      <td>370.270000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-01</th>\n",
       "      <td>13.923281</td>\n",
       "      <td>1.400648e+10</td>\n",
       "      <td>74.430605</td>\n",
       "      <td>19.25</td>\n",
       "      <td>1.1458</td>\n",
       "      <td>358.38</td>\n",
       "      <td>19.366667</td>\n",
       "      <td>1.190267</td>\n",
       "      <td>361.850000</td>\n",
       "      <td>14.597519</td>\n",
       "      <td>1.386282e+10</td>\n",
       "      <td>74.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05-01</th>\n",
       "      <td>13.698535</td>\n",
       "      <td>1.404985e+10</td>\n",
       "      <td>74.312644</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1.0622</td>\n",
       "      <td>356.95</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.139433</td>\n",
       "      <td>359.556667</td>\n",
       "      <td>14.372773</td>\n",
       "      <td>1.391355e+10</td>\n",
       "      <td>74.690804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Revenue, excluding grants (% of GDP)  GDP (constant 2015 US$)  \\\n",
       "date                                                                        \n",
       "1991-01-01                             14.597519             1.386282e+10   \n",
       "1991-02-01                             14.372773             1.391355e+10   \n",
       "1991-03-01                             14.148027             1.396124e+10   \n",
       "1991-04-01                             13.923281             1.400648e+10   \n",
       "1991-05-01                             13.698535             1.404985e+10   \n",
       "\n",
       "            Employment to population ratio (15+, total %)  \\\n",
       "date                                                        \n",
       "1991-01-01                                      74.834000   \n",
       "1991-02-01                                      74.690804   \n",
       "1991-03-01                                      74.556498   \n",
       "1991-04-01                                      74.430605   \n",
       "1991-05-01                                      74.312644   \n",
       "\n",
       "            Crude Oil Brent Price  Cocoa Price  Gold Price  \\\n",
       "date                                                         \n",
       "1991-01-01                  23.65       1.2417      383.64   \n",
       "1991-02-01                  19.40       1.2147      363.83   \n",
       "1991-03-01                  19.45       1.2103      363.34   \n",
       "1991-04-01                  19.25       1.1458      358.38   \n",
       "1991-05-01                  19.30       1.0622      356.95   \n",
       "\n",
       "            Crude Oil Brent Price_3mo_ma  Cocoa Price_3mo_ma  \\\n",
       "date                                                           \n",
       "1991-01-01                     23.650000            1.241700   \n",
       "1991-02-01                     21.525000            1.228200   \n",
       "1991-03-01                     20.833333            1.222233   \n",
       "1991-04-01                     19.366667            1.190267   \n",
       "1991-05-01                     19.333333            1.139433   \n",
       "\n",
       "            Gold Price_3mo_ma  Revenue, excluding grants (% of GDP)_lag3  \\\n",
       "date                                                                       \n",
       "1991-01-01         383.640000                                        NaN   \n",
       "1991-02-01         373.735000                                        NaN   \n",
       "1991-03-01         370.270000                                        NaN   \n",
       "1991-04-01         361.850000                                  14.597519   \n",
       "1991-05-01         359.556667                                  14.372773   \n",
       "\n",
       "            GDP (constant 2015 US$)_lag3  \\\n",
       "date                                       \n",
       "1991-01-01                           NaN   \n",
       "1991-02-01                           NaN   \n",
       "1991-03-01                           NaN   \n",
       "1991-04-01                  1.386282e+10   \n",
       "1991-05-01                  1.391355e+10   \n",
       "\n",
       "            Employment to population ratio (15+, total %)_lag3  \n",
       "date                                                            \n",
       "1991-01-01                                                NaN   \n",
       "1991-02-01                                                NaN   \n",
       "1991-03-01                                                NaN   \n",
       "1991-04-01                                          74.834000   \n",
       "1991-05-01                                          74.690804   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cf9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
