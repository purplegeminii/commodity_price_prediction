{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408 entries, 0 to 407\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   date                                           408 non-null    object \n",
      " 1   Revenue, excluding grants (% of GDP)           408 non-null    float64\n",
      " 2   GDP (constant 2015 US$)                        408 non-null    float64\n",
      " 3   Employment to population ratio (15+, total %)  408 non-null    float64\n",
      " 4   Crude Oil Brent Price                          408 non-null    float64\n",
      " 5   Cocoa Price                                    408 non-null    float64\n",
      " 6   Gold Price                                     408 non-null    float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 22.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"merged_macro_commodity.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plotting(title, data, x, y, x_label, y_label, text=False, lam=None):\n",
    "    \"\"\"General function to plot the data.\"\"\"\n",
    "    fig = px.line(data, x=data[x], y=data[y], labels={x: x_label, y: y_label})\n",
    "    fig.update_layout(template=\"simple_white\", font=dict(size=18), title_text=title, width=650, title_x=0.5, height=400)\n",
    "    if text:\n",
    "      fig.add_annotation(\n",
    "          x='1952-12-20', y=10, text=f'Lambda = {lam:.3f}',\n",
    "          align='left', yanchor='bottom', showarrow=False,\n",
    "          font=dict(size=20, color=\"black\", family=\"Courier New, monospace\"),\n",
    "          bordercolor='black', borderwidth=2, bgcolor=\"white\"\n",
    "      )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def add_separator(width=650):\n",
    "    \"\"\"Add a horizontal line as a separator.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    fig.add_hline(y=0.5, line_dash=\"dot\", line_color=\"gray\", line_width=2)\n",
    "    fig.update_layout(height=50, width=width, margin=dict(l=20, r=20, t=20, b=20), xaxis_visible=False, yaxis_visible=False)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(title='Revenue Over Time', data=data, x='date', y='Revenue, excluding grants (% of GDP)', x_label='Date', y_label='%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add volatility as an additional target\n",
    "df['CrudeOil_Volatility'] = df['Crude Oil Brent Price'].pct_change().rolling(12).std()\n",
    "df['Cocoa_Volatility'] = df['Cocoa Price'].pct_change().rolling(12).std()\n",
    "df['Gold_Volatility'] = df['Gold Price'].pct_change().rolling(12).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, root_mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Prepare volatility features\n",
    "for commodity in ['Crude Oil Brent Price', 'Cocoa Price', 'Gold Price']:\n",
    "    df[f'{commodity.split()[0]}_Volatility'] = df[commodity].pct_change().rolling(12).std()\n",
    "\n",
    "# Define features and targets\n",
    "features = [\n",
    "    'Revenue, excluding grants (% of GDP)', \n",
    "    'GDP (constant 2015 US$)', \n",
    "    'Employment to population ratio (15+, total %)',\n",
    "    'CrudeOil_Volatility',\n",
    "    'Cocoa_Volatility',\n",
    "    'Gold_Volatility'\n",
    "]\n",
    "targets = ['Crude Oil Brent Price', 'Cocoa Price', 'Gold Price']\n",
    "\n",
    "# Handle missing values from volatility calculation\n",
    "df = df.dropna()\n",
    "\n",
    "# Scale features and targets separately\n",
    "feature_scaler = RobustScaler()\n",
    "target_scaler = RobustScaler()\n",
    "\n",
    "X_scaled = feature_scaler.fit_transform(df[features])\n",
    "y_scaled = target_scaler.fit_transform(df[targets])\n",
    "\n",
    "# Create sequences with 12-month lookback\n",
    "def create_sequences(X, y, n_steps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(n_steps, len(X)):\n",
    "        X_seq.append(X[i-n_steps:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "n_steps = 12\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, n_steps)\n",
    "\n",
    "# Build enhanced LSTM model with volatility awareness\n",
    "model = Sequential([\n",
    "    # First LSTM layer with attention to volatility\n",
    "    LSTM(256, activation='tanh', \n",
    "         input_shape=(n_steps, len(features)),\n",
    "         kernel_regularizer=L1L2(l1=1e-5, l2=1e-4),\n",
    "         return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    LSTM(128, activation='tanh',\n",
    "         kernel_regularizer=L1L2(l1=1e-5, l2=1e-4)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Volatility-conditioned dense layers\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    \n",
    "    # Final output layer\n",
    "    Dense(len(targets))\n",
    "])\n",
    "\n",
    "# Custom learning rate with decay\n",
    "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "# Train with temporal cross-validation\n",
    "test_size = int(0.2 * len(X_seq))\n",
    "X_train, X_test = X_seq[:-test_size], X_seq[-test_size:]\n",
    "y_train, y_test = y_seq[:-test_size], y_seq[-test_size:]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate with walk-forward validation\n",
    "def evaluate_walk_forward(X, y, model, steps):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    for i in range(steps):\n",
    "        x_input = X[-(steps-i)].reshape(1, n_steps, X.shape[2])\n",
    "        y_pred = model.predict(x_input, verbose=0)\n",
    "        predictions.append(y_pred[0])\n",
    "        actuals.append(y[-(steps-i)])\n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "preds, actuals = evaluate_walk_forward(X_seq, y_seq, model, test_size)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "actuals = target_scaler.inverse_transform(actuals)\n",
    "\n",
    "# Commodity-specific evaluation\n",
    "results = {}\n",
    "for i, target in enumerate(targets):\n",
    "    mape = mean_absolute_percentage_error(actuals[:, i], preds[:, i])\n",
    "    rmse = root_mean_squared_error(actuals[:, i], preds[:, i])\n",
    "    results[target] = {'MAPE': mape*100, 'RMSE': rmse}\n",
    "    print(f\"{target.upper():<25} MAPE: {mape*100:.2f}% | RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Feature importance analysis (permutation importance)\n",
    "def calculate_permutation_importance(model, X_test, y_test, n_iterations=10):\n",
    "    baseline = model.evaluate(X_test, y_test, verbose=0)[0]\n",
    "    importance = {i: 0 for i in range(len(features))}\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        X_temp = X_test.copy()\n",
    "        for _ in range(n_iterations):\n",
    "            X_temp[:, :, i] = np.random.permutation(X_temp[:, :, i])\n",
    "            loss = model.evaluate(X_temp, y_test, verbose=0)[0]\n",
    "            importance[i] += (loss - baseline)/n_iterations\n",
    "            \n",
    "    return {features[k]: v for k, v in importance.items()}\n",
    "\n",
    "perm_importance = calculate_permutation_importance(model, X_test, y_test)\n",
    "print(\"\\nFeature Importance:\")\n",
    "for feat, imp in sorted(perm_importance.items(), key=lambda x: abs(x[1]), reverse=True):\n",
    "    print(f\"{feat:<35} {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = model.history.history['loss']\n",
    "plt.plot(range(len(loss_per_epoch)),loss_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
